{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'detections_no_desc/graal_1/yolo.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d658f804818c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/%s_videos'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimage_id_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_id_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboat_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtracking_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracking_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yara_thesis/MSThesis_Code/Video tracking/utils.py\u001b[0m in \u001b[0;36mload_detections\u001b[0;34m(dataset, detector, boat_class, min_conf)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_detections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mboat_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtext_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"detections_no_desc/%s/%s.txt\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdetector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdetections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'detections_no_desc/graal_1/yolo.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import motmetrics as mm\n",
    "import imutils\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import cv2 as cv\n",
    "import time\n",
    "#from sort import *\n",
    "\n",
    "import json\n",
    "from utils import load_detections\n",
    "\n",
    "from detection import Detection\n",
    "from track import Track\n",
    "from tracker import Tracker\n",
    "\n",
    "\n",
    "\n",
    "colors = [[0,0,128],[0,255,0],[0,0,255],[255,0,0],[0,128,128],[128,0,128],[128,128,0],[255,255,0],[0,255,255],[255,255,0],[128,0,0],[0,128,0]\n",
    "         ,[0,128,255],[0,255,128],[255,0,128],[128,255,0],[255,128,0],[128,255,255],[128,0,255],[128,128,128],[128,255,128]]\n",
    "tracking_methods=['kalman_acc','kalman_vel']\n",
    "\n",
    "#tracking_methods=['center_flow','keypoint_flow','kalman_center','kalman_corners','SORT']\n",
    "detectors = ['yolo']\n",
    "#detectors = ['ssd300','retinanet','yolo']\n",
    "#'center_fow','keypoint_flow','kalman_center','kalman_corners',\n",
    "datasets=['graal_1','graal_2','graal_3','graal_4']\n",
    "times = {}\n",
    "for dataset in datasets:\n",
    "    times[dataset]={}\n",
    "    images_input_path='../%s/'%dataset\n",
    "    image_id_prefix= dataset\n",
    "    frame_width=1032\n",
    "    frame_height=778\n",
    "   \n",
    "    \n",
    "    for detector in detectors:\n",
    "        times[dataset][detector] = {}\n",
    "        boat_class=8\n",
    "        min_conf=0\n",
    "        if(detector=='ssd300'):\n",
    "            boat_class=4\n",
    "            \n",
    "        if(detector=='def'):\n",
    "            boat_class=1\n",
    "        \n",
    "\n",
    "        path = '%s/%s_videos'%(detector,image_id_prefix)\n",
    "        detections = load_detections(image_id_prefix,detector,boat_class,min_conf)\n",
    "        \n",
    "        for tracking_method in tracking_methods:\n",
    "            times[dataset][detector][tracking_method] = []\n",
    "            video_output_path='%s/%s(%.1f conf).avi'%(path,tracking_method,min_conf)\n",
    "            json_output_path='%s/%s(%.1f conf).json'%(path,tracking_method,min_conf)\n",
    "            out_tracking = cv.VideoWriter(video_output_path,cv.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "            frameCount =0\n",
    "            no_tracking_res = [] \n",
    "            tracking_res = []\n",
    "            kalman_trackers=[]\n",
    "            # initialize the first frame in the video stream\n",
    "            frameCount =0\n",
    "            \n",
    "            print('Running: Dataset:%s, Detector:%s, Tracker:%s, @%dx%d, File Name %s'%(dataset,detector,tracking_method,frame_width,frame_height,video_output_path))\n",
    "            preds = []\n",
    "            tracks=[]\n",
    "            \n",
    "            \n",
    "            prev_frame=None\n",
    "            \n",
    "            total_frames=900\n",
    "            \n",
    "            \n",
    "            tracker_wrapper = Tracker(tracking_method)\n",
    "            tracker_wrapper.frame_width = frame_width\n",
    "            tracker_wrapper.frame_height = frame_height\n",
    "                \n",
    "            while frameCount<total_frames:\n",
    "                \n",
    "                # grab the current frame and initialize the occupied/unoccupied\n",
    "                # text\n",
    "                frame = cv.imread('%s%s.jpg'%(images_input_path,str(frameCount+1).zfill(5)))\n",
    "                \n",
    "                if frame is None:\n",
    "                    break\n",
    "\n",
    "                if(frameCount<0):\n",
    "                    continue\n",
    "\n",
    "                preds = []\n",
    "                \n",
    "                start= time.time()\n",
    "                \n",
    "                \n",
    "                if '%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5)) in detections:\n",
    "                    preds = detections['%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5))]\n",
    "                \n",
    "                for det in preds:\n",
    "                    det.calc_hog_descriptor(frame)\n",
    "                    \n",
    "                \n",
    "                tracker_wrapper.track(preds,frame,prev_frame)\n",
    "\n",
    "\n",
    "                to_display = tracker_wrapper.get_display_tracks()\n",
    "\n",
    "                i=0\n",
    "                for box in to_display:\n",
    "                    \n",
    "                # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "                   \n",
    "                    xmin = int(box.xmin)\n",
    "                    ymin = int(box.ymin)\n",
    "                    xmax =int(box.xmax)\n",
    "                    ymax =int(box.ymax)\n",
    "                    \n",
    "                    cv.rectangle(frame, (int(xmin), int(ymin)), (int(xmax),int(ymax)), colors[int(box.track_id)%len(colors)], 3)\n",
    "                    cv.putText(frame,'{:.2f}'.format( box.conf), (xmin, ymin),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    tracking_res.append({\"image_id\" : frameCount+1, \"category_id\" : 1, \"bbox\" : [float(xmin),float(ymin),float(xmax-xmin),float(ymax-ymin)],\"id\":box.track_id, \"score\" :1})# np.minimum(1.0,np.maximum(box.conf,0.5))})\n",
    "                    i+=1\n",
    "                    times[dataset][detector][tracking_method].append(time.time()-start)\n",
    "                \n",
    "                out_tracking.write(frame)\n",
    "                frameCount+=1\n",
    "                prev_frame=frame\n",
    "                \n",
    "\n",
    "            out_tracking.release()\n",
    "            \n",
    "            with open(json_output_path, 'w') as outfile:  \n",
    "                json.dump(tracking_res, outfile)\n",
    "                \n",
    "for k in times.keys():\n",
    "    print(k)\n",
    "    yolo = times[k]['yolo']\n",
    "    for tr in yolo.keys():\n",
    "        print(tr,np.average(yolo[tr]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv.KalmanFilter??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Dataset:graal_4, Detector:ssd300, Tracker:SORT, @1032x778\n",
      "graal_4\n",
      "SORT 0.0009647131872721045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import motmetrics as mm\n",
    "import imutils\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import cv2 as cv\n",
    "import time\n",
    "from sort import *\n",
    "\n",
    "import json\n",
    "from utils import load_detections\n",
    "\n",
    "from detection import Detection\n",
    "from track import Track\n",
    "from tracker import Tracker\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "total_frames=900\n",
    "iou_overlaps = []\n",
    "desc_dists = []\n",
    "confusion_frames = []\n",
    "confusion_tracks = []\n",
    "confusion_distances =[]\n",
    "colors = [[0,0,128],[0,255,0],[0,0,255],[255,0,0],[0,128,128],[128,0,128],[128,128,0],[255,255,0],[0,255,255],[255,255,0],[128,0,0],[0,128,0]\n",
    "         ,[0,128,255],[0,255,128],[255,0,128],[128,255,0],[255,128,0],[128,255,255],[128,0,255],[128,128,128],[128,255,128]]\n",
    "tracking_methods=['SORT']\n",
    "#tracking_methods=['center_flow','keypoint_flow','kalman_center','kalman_corners','SORT']\n",
    "detectors = ['ssd300']\n",
    "#detectors = ['ssd300','retinanet','yolo']\n",
    "#'center_fow','keypoint_flow','kalman_center','kalman_corners',\n",
    "datasets=['graal_4']\n",
    "times = {}\n",
    "for dataset in datasets:\n",
    "    times[dataset]={}\n",
    "    images_input_path='../%s/'%dataset\n",
    "    image_id_prefix= dataset\n",
    "    frame_width=1032\n",
    "    frame_height=778\n",
    "    if(dataset=='venc'):\n",
    "        frame_width = 1280\n",
    "        frame_height = 960\n",
    "    if(dataset=='modd'):\n",
    "        frame_width=640\n",
    "        frame_height=464\n",
    "    if(dataset=='garda_1' or dataset=='garda_2'):\n",
    "        frame_width=1280\n",
    "        frame_height=720\n",
    "    if(dataset=='mot_1'):\n",
    "        frame_width=768\n",
    "        frame_height=576\n",
    "    \n",
    "    for detector in detectors:\n",
    "        times[dataset][detector] = {}\n",
    "        boat_class=8\n",
    "        min_conf=0\n",
    "        if(detector=='ssd300'):\n",
    "            boat_class=4\n",
    "            min_conf=0\n",
    "        if(detector=='def'):\n",
    "            boat_class=1\n",
    "        \n",
    "\n",
    "        path = '%s/%s_videos'%(detector,image_id_prefix)\n",
    "        detections = load_detections(image_id_prefix,detector,boat_class,0.5)\n",
    "        \n",
    "        for tracking_method in tracking_methods:\n",
    "            times[dataset][detector][tracking_method] = []\n",
    "            video_output_path='%s/%s.avi'%(path,tracking_method)\n",
    "            json_output_path='%s/%s.json'%(path,tracking_method)\n",
    "            out_tracking = cv.VideoWriter(video_output_path,cv.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "            frameCount =0\n",
    "            \n",
    "            # initialize the first frame in the video stream\n",
    "            \n",
    "            \n",
    "            print('Running: Dataset:%s, Detector:%s, Tracker:%s, @%dx%d'%(dataset,detector,tracking_method,frame_width,frame_height))\n",
    "            preds = []\n",
    "            if(tracking_method=='SORT'):\n",
    "                mot_tracker = Sort()\n",
    "            tracking_res = []\n",
    "            while frameCount<total_frames:\n",
    "                \n",
    "                # grab the current frame and initialize the occupied/unoccupied\n",
    "                # text\n",
    "                frame = cv.imread('%s%s.jpg'%(images_input_path,str(frameCount+1).zfill(5)))\n",
    "                \n",
    "                \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # if the frame could not be grabbed, then we have reached the end\n",
    "                # of the video\n",
    "                if frame is None:\n",
    "                    break\n",
    "\n",
    "                if(frameCount<0):\n",
    "                    continue\n",
    "\n",
    "                preds = []\n",
    "                if '%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5)) in detections:\n",
    "\n",
    "                    for box in detections['%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5))]:\n",
    "\n",
    "                        if(box.conf<min_conf):\n",
    "\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        temp_pred =  np.array([box.xmin,box.ymin,box.xmax,box.ymax,box.conf])\n",
    "\n",
    "                        preds.append(temp_pred)\n",
    "                        \n",
    "                          \n",
    "                \n",
    "                start= time.time()\n",
    "                if(tracking_method=='SORT'):\n",
    "                    preds = np.asarray(preds)\n",
    "                    trackers = mot_tracker.update(preds)\n",
    "                    to_display = []\n",
    "                    for itrk,tracker in enumerate(trackers):\n",
    "                        to_display.append(np.array([tracker[4],tracker[0],tracker[1],tracker[2],tracker[3]]))\n",
    "               \n",
    "                i=0\n",
    "                for box in to_display:\n",
    "                    \n",
    "                # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "                   \n",
    "                    xmin = int(box[1])\n",
    "                    ymin = int(box[2])\n",
    "                    xmax =int(box[3])\n",
    "                    ymax =int(box[4])\n",
    "                    \n",
    "                    cv.rectangle(frame, (int(xmin), int(ymin)), (int(xmax),int(ymax)), colors[int(box[0])%len(colors)], 3)\n",
    "                    \n",
    "\n",
    "                    tracking_res.append({\"image_id\" : frameCount+1, \"category_id\" : 1, \"bbox\" : [float(xmin),float(ymin),float(xmax-xmin),float(ymax-ymin)], \"score\" : 1.0,\"id\":int(box[0])})\n",
    "                    i+=1\n",
    "                    times[dataset][detector][tracking_method].append(time.time()-start)\n",
    "                \n",
    "                out_tracking.write(frame)\n",
    "                #cv.imwrite('debug_frames/%s.jpg'%str(frameCount+1),frame)\n",
    "                frameCount+=1\n",
    "                prev_frame=frame\n",
    "                flow = None\n",
    "            # cleanup the camera and close any open windows\n",
    "\n",
    "            out_tracking.release()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            with open(json_output_path, 'w') as outfile:  \n",
    "                json.dump(tracking_res, outfile)\n",
    "                \n",
    "for k in times.keys():\n",
    "    print(k)\n",
    "    yolo = times[k]['ssd300']\n",
    "    for tr in yolo.keys():\n",
    "        print(tr,np.average(yolo[tr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

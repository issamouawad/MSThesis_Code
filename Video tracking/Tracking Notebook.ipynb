{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Dataset:graal_1, Detector:yolo, Tracker:kalman_acc, @1032x778, File Name yolo/graal_1_videos/kalman_acc(0.0 conf).avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\issam\\Anaconda3\\lib\\site-packages\\skimage\\feature\\_hog.py:150: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15. To supress this message specify explicitly the normalization method.\n",
      "  skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Dataset:graal_1, Detector:yolo, Tracker:kalman_vel, @1032x778, File Name yolo/graal_1_videos/kalman_vel(0.0 conf).avi\n",
      "Running: Dataset:graal_2, Detector:yolo, Tracker:kalman_acc, @1032x778, File Name yolo/graal_2_videos/kalman_acc(0.0 conf).avi\n",
      "Running: Dataset:graal_2, Detector:yolo, Tracker:kalman_vel, @1032x778, File Name yolo/graal_2_videos/kalman_vel(0.0 conf).avi\n",
      "Running: Dataset:graal_3, Detector:yolo, Tracker:kalman_acc, @1032x778, File Name yolo/graal_3_videos/kalman_acc(0.0 conf).avi\n",
      "Running: Dataset:graal_3, Detector:yolo, Tracker:kalman_vel, @1032x778, File Name yolo/graal_3_videos/kalman_vel(0.0 conf).avi\n",
      "Running: Dataset:graal_4, Detector:yolo, Tracker:kalman_acc, @1032x778, File Name yolo/graal_4_videos/kalman_acc(0.0 conf).avi\n",
      "Running: Dataset:graal_4, Detector:yolo, Tracker:kalman_vel, @1032x778, File Name yolo/graal_4_videos/kalman_vel(0.0 conf).avi\n",
      "graal_1\n",
      "kalman_acc 0.016713756653997634\n",
      "kalman_vel 0.016737702289058586\n",
      "graal_2\n",
      "kalman_acc 0.033231061161234136\n",
      "kalman_vel 0.026443946327866806\n",
      "graal_3\n",
      "kalman_acc 0.008052158513867836\n",
      "kalman_vel 0.007933293211321728\n",
      "graal_4\n",
      "kalman_acc 0.005881471537417947\n",
      "kalman_vel 0.004592204777426502\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import motmetrics as mm\n",
    "import imutils\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import cv2 as cv\n",
    "import time\n",
    "from sort import *\n",
    "\n",
    "import json\n",
    "from utils import load_detections\n",
    "\n",
    "from detection import Detection\n",
    "from track import Track\n",
    "from tracker import Tracker\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "iou_overlaps = []\n",
    "desc_dists = []\n",
    "confusion_frames = []\n",
    "confusion_tracks = []\n",
    "confusion_distances =[]\n",
    "colors = [[0,0,128],[0,255,0],[0,0,255],[255,0,0],[0,128,128],[128,0,128],[128,128,0],[255,255,0],[0,255,255],[255,255,0],[128,0,0],[0,128,0]\n",
    "         ,[0,128,255],[0,255,128],[255,0,128],[128,255,0],[255,128,0],[128,255,255],[128,0,255],[128,128,128],[128,255,128]]\n",
    "tracking_methods=['kalman_acc','kalman_vel']\n",
    "\n",
    "#tracking_methods=['center_flow','keypoint_flow','kalman_center','kalman_corners','SORT']\n",
    "detectors = ['yolo']\n",
    "#detectors = ['ssd300','retinanet','yolo']\n",
    "#'center_fow','keypoint_flow','kalman_center','kalman_corners',\n",
    "datasets=['graal_1','graal_2','graal_3','graal_4']\n",
    "times = {}\n",
    "for dataset in datasets:\n",
    "    times[dataset]={}\n",
    "    images_input_path='../%s/'%dataset\n",
    "    image_id_prefix= dataset\n",
    "    frame_width=1032\n",
    "    frame_height=778\n",
    "    if(dataset=='venc'):\n",
    "        frame_width = 1280\n",
    "        frame_height = 960\n",
    "    if(dataset=='modd'):\n",
    "        frame_width=640\n",
    "        frame_height=464\n",
    "    if(dataset=='garda_1' or dataset=='garda_2'):\n",
    "        frame_width=1280\n",
    "        frame_height=720\n",
    "    if(dataset=='mot_1'):\n",
    "        frame_width=768\n",
    "        frame_height=576\n",
    "    iou_threshold = 0.1\n",
    "    for detector in detectors:\n",
    "        times[dataset][detector] = {}\n",
    "        boat_class=8\n",
    "        min_conf=0\n",
    "        if(detector=='ssd300'):\n",
    "            boat_class=4\n",
    "            \n",
    "        if(detector=='def'):\n",
    "            boat_class=1\n",
    "        \n",
    "\n",
    "        path = '%s/%s_videos'%(detector,image_id_prefix)\n",
    "        detections = load_detections(image_id_prefix,detector,boat_class,min_conf)\n",
    "        \n",
    "        for tracking_method in tracking_methods:\n",
    "            times[dataset][detector][tracking_method] = []\n",
    "            video_output_path='%s/%s(%.1f conf).avi'%(path,tracking_method,min_conf)\n",
    "            json_output_path='%s/%s(%.1f conf).json'%(path,tracking_method,min_conf)\n",
    "            out_tracking = cv.VideoWriter(video_output_path,cv.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "            frameCount =0\n",
    "            no_tracking_res = [] \n",
    "            tracking_res = []\n",
    "            kalman_trackers=[]\n",
    "            # initialize the first frame in the video stream\n",
    "            frameCount =0\n",
    "            step_up = 0.1\n",
    "            step_down = 0.2\n",
    "            print('Running: Dataset:%s, Detector:%s, Tracker:%s, @%dx%d, File Name %s'%(dataset,detector,tracking_method,frame_width,frame_height,video_output_path))\n",
    "            preds = []\n",
    "            tracks=[]\n",
    "            started = False\n",
    "            multiplier=0\n",
    "            cc=0\n",
    "            prev_frame=None\n",
    "            \n",
    "            total_frames=900\n",
    "            if(tracking_method=='SORT'):\n",
    "                mot_tracker = Sort()\n",
    "            else:\n",
    "                tracker_wrapper = Tracker(tracking_method)\n",
    "                tracker_wrapper.frame_width = frame_width\n",
    "                tracker_wrapper.frame_height = frame_height\n",
    "                if(dataset=='modd'):\n",
    "                    tracker_wrapper.A = np.array([int(frame_width/2),int(frame_height/2)])\n",
    "                    tracker_wrapper.B = np.array([int(frame_width/5),int(frame_height-1)])\n",
    "                    tracker_wrapper.C= np.array([int(4*frame_width/5),frame_height-1])\n",
    "                elif(dataset=='graal_1' or dataset == 'graal_2' or dataset=='garda_1' or dataset=='garda_2'):\n",
    "                    tracker_wrapper.A = np.array([int(frame_width/2),int(frame_height/2)])\n",
    "                    tracker_wrapper.B = np.array([int(frame_width/5),int(frame_height-1)])\n",
    "                    tracker_wrapper.C= np.array([int(4*frame_width/5),frame_height-1])\n",
    "            while frameCount<total_frames:\n",
    "                \n",
    "                # grab the current frame and initialize the occupied/unoccupied\n",
    "                # text\n",
    "                frame = cv.imread('%s%s.jpg'%(images_input_path,str(frameCount+1).zfill(5)))\n",
    "                \n",
    "                \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # if the frame could not be grabbed, then we have reached the end\n",
    "                # of the video\n",
    "                if frame is None:\n",
    "                    break\n",
    "\n",
    "                if(frameCount<0):\n",
    "                    continue\n",
    "\n",
    "                preds = []\n",
    "                \n",
    "                start= time.time()\n",
    "                \n",
    "                \n",
    "                if '%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5)) in detections:\n",
    "                    preds = detections['%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5))]\n",
    "                \n",
    "                for det in preds:\n",
    "                    det.calc_hog_descriptor(frame)\n",
    "                    \n",
    "                \n",
    "                tracker_wrapper.track(preds,frame,prev_frame)\n",
    "\n",
    "\n",
    "                to_display = tracker_wrapper.get_display_tracks()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    #print(acc.mot_events.loc[frameId])\n",
    "               \n",
    "                col_points = []#tracker_wrapper.get_collision_points()\n",
    "                if(len(col_points)>0):\n",
    "                    col = [0,0,255]\n",
    "                    cv.putText(frame,'Collision detected!', (20, 20),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    \n",
    "                \n",
    "                else:\n",
    "                    col = [0,255,255]\n",
    "                \n",
    "                \n",
    "               \n",
    "                \n",
    "                for p in col_points:\n",
    "                    cv.circle(frame,(int(p[0]),int(p[1])),8,(0,0,255),1)\n",
    "                i=0\n",
    "                for box in to_display:\n",
    "                    \n",
    "                # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "                   \n",
    "                    xmin = int(box.xmin)\n",
    "                    ymin = int(box.ymin)\n",
    "                    xmax =int(box.xmax)\n",
    "                    ymax =int(box.ymax)\n",
    "                    \n",
    "                    cv.rectangle(frame, (int(xmin), int(ymin)), (int(xmax),int(ymax)), colors[int(box.track_id)%len(colors)], 3)\n",
    "                    #cv.rectangle(frame, (int(box.new_box[0] - box.new_box[2]/2), int(box.new_box[1] - box.new_box[3]/2)), (int(box.new_box[0] + box.new_box[2]/2),int(box.new_box[1] + box.new_box[3]/2)), (255,255,255), 2)\n",
    "                    p1 = box.center()\n",
    "                    p2 = box.center()\n",
    "                    p2[0] += box.offset[0]*3\n",
    "                    p2[1] += box.offset[1]*100\n",
    "                    \n",
    "                    #cv.arrowedLine(frame,(int(p1[0]),int(p1[1])),(int(p2[0]),int(p2[1])),(0,0,255),2)\n",
    "                    if(tracking_method=='kalman_center'):\n",
    "                        \n",
    "                        cv.circle(frame,(int(predictions[i][0][0]),int(predictions[i][1][0])),5,(255,0,0),2)\n",
    "                    #if(tracking_method=='kalman_corners'):\n",
    "                        #cv.circle(frame,(int(predictions[i][0][0]),int(predictions[i][1][0])),5,(255,0,0),2)\n",
    "                        #cv.circle(frame,(int(predictions[i][2][0]),int(predictions[i][3][0])),5,(255,0,0),2)\n",
    "                    cv.putText(frame,'{:.2f}'.format( box.conf), (xmin, ymin),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    \n",
    "\n",
    "                    tracking_res.append({\"image_id\" : frameCount+1, \"category_id\" : 1, \"bbox\" : [float(xmin),float(ymin),float(xmax-xmin),float(ymax-ymin)],\"id\":box.track_id, \"score\" :1})# np.minimum(1.0,np.maximum(box.conf,0.5))})\n",
    "                    #f.write(\"graal_2/%s.jpg,%s,%d,%f,%f,%f,%f,%f\\n\"%(str(frameCount+1).zfill(5),classes[int(box[1])],box[1],box[2],xmin,ymin,xmax,ymax))\n",
    "                    i+=1\n",
    "                    times[dataset][detector][tracking_method].append(time.time()-start)\n",
    "                \n",
    "                out_tracking.write(frame)\n",
    "                #cv.imwrite('debug_frames/%s.jpg'%str(frameCount+1),frame)\n",
    "                frameCount+=1\n",
    "                prev_frame=frame\n",
    "                flow = None\n",
    "            # cleanup the camera and close any open windows\n",
    "\n",
    "            out_tracking.release()\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "            with open(json_output_path, 'w') as outfile:  \n",
    "                json.dump(tracking_res, outfile)\n",
    "                \n",
    "for k in times.keys():\n",
    "    print(k)\n",
    "    yolo = times[k]['yolo']\n",
    "    for tr in yolo.keys():\n",
    "        print(tr,np.average(yolo[tr]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(min_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv.KalmanFilter??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Dataset:graal_4, Detector:ssd300, Tracker:SORT, @1032x778\n",
      "graal_4\n",
      "SORT 0.0009647131872721045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import motmetrics as mm\n",
    "import imutils\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import cv2 as cv\n",
    "import time\n",
    "from sort import *\n",
    "\n",
    "import json\n",
    "from utils import load_detections\n",
    "\n",
    "from detection import Detection\n",
    "from track import Track\n",
    "from tracker import Tracker\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "total_frames=900\n",
    "iou_overlaps = []\n",
    "desc_dists = []\n",
    "confusion_frames = []\n",
    "confusion_tracks = []\n",
    "confusion_distances =[]\n",
    "colors = [[0,0,128],[0,255,0],[0,0,255],[255,0,0],[0,128,128],[128,0,128],[128,128,0],[255,255,0],[0,255,255],[255,255,0],[128,0,0],[0,128,0]\n",
    "         ,[0,128,255],[0,255,128],[255,0,128],[128,255,0],[255,128,0],[128,255,255],[128,0,255],[128,128,128],[128,255,128]]\n",
    "tracking_methods=['SORT']\n",
    "#tracking_methods=['center_flow','keypoint_flow','kalman_center','kalman_corners','SORT']\n",
    "detectors = ['ssd300']\n",
    "#detectors = ['ssd300','retinanet','yolo']\n",
    "#'center_fow','keypoint_flow','kalman_center','kalman_corners',\n",
    "datasets=['graal_4']\n",
    "times = {}\n",
    "for dataset in datasets:\n",
    "    times[dataset]={}\n",
    "    images_input_path='../%s/'%dataset\n",
    "    image_id_prefix= dataset\n",
    "    frame_width=1032\n",
    "    frame_height=778\n",
    "    if(dataset=='venc'):\n",
    "        frame_width = 1280\n",
    "        frame_height = 960\n",
    "    if(dataset=='modd'):\n",
    "        frame_width=640\n",
    "        frame_height=464\n",
    "    if(dataset=='garda_1' or dataset=='garda_2'):\n",
    "        frame_width=1280\n",
    "        frame_height=720\n",
    "    if(dataset=='mot_1'):\n",
    "        frame_width=768\n",
    "        frame_height=576\n",
    "    iou_threshold = 0.1\n",
    "    for detector in detectors:\n",
    "        times[dataset][detector] = {}\n",
    "        boat_class=8\n",
    "        min_conf=0\n",
    "        if(detector=='ssd300'):\n",
    "            boat_class=4\n",
    "            min_conf=0\n",
    "        if(detector=='def'):\n",
    "            boat_class=1\n",
    "        \n",
    "\n",
    "        path = '%s/%s_videos'%(detector,image_id_prefix)\n",
    "        detections = load_detections(image_id_prefix,detector,boat_class,0.5)\n",
    "        \n",
    "        for tracking_method in tracking_methods:\n",
    "            times[dataset][detector][tracking_method] = []\n",
    "            video_output_path='%s/%s.avi'%(path,tracking_method)\n",
    "            json_output_path='%s/%s.json'%(path,tracking_method)\n",
    "            out_tracking = cv.VideoWriter(video_output_path,cv.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "            frameCount =0\n",
    "            \n",
    "            # initialize the first frame in the video stream\n",
    "            \n",
    "            \n",
    "            print('Running: Dataset:%s, Detector:%s, Tracker:%s, @%dx%d'%(dataset,detector,tracking_method,frame_width,frame_height))\n",
    "            preds = []\n",
    "            if(tracking_method=='SORT'):\n",
    "                mot_tracker = Sort()\n",
    "            tracking_res = []\n",
    "            while frameCount<total_frames:\n",
    "                \n",
    "                # grab the current frame and initialize the occupied/unoccupied\n",
    "                # text\n",
    "                frame = cv.imread('%s%s.jpg'%(images_input_path,str(frameCount+1).zfill(5)))\n",
    "                \n",
    "                \n",
    "                    \n",
    "                \n",
    "                \n",
    "                # if the frame could not be grabbed, then we have reached the end\n",
    "                # of the video\n",
    "                if frame is None:\n",
    "                    break\n",
    "\n",
    "                if(frameCount<0):\n",
    "                    continue\n",
    "\n",
    "                preds = []\n",
    "                if '%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5)) in detections:\n",
    "\n",
    "                    for box in detections['%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5))]:\n",
    "\n",
    "                        if(box.conf<min_conf):\n",
    "\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        temp_pred =  np.array([box.xmin,box.ymin,box.xmax,box.ymax,box.conf])\n",
    "\n",
    "                        preds.append(temp_pred)\n",
    "                        \n",
    "                          \n",
    "                \n",
    "                start= time.time()\n",
    "                if(tracking_method=='SORT'):\n",
    "                    preds = np.asarray(preds)\n",
    "                    trackers = mot_tracker.update(preds)\n",
    "                    to_display = []\n",
    "                    for itrk,tracker in enumerate(trackers):\n",
    "                        to_display.append(np.array([tracker[4],tracker[0],tracker[1],tracker[2],tracker[3]]))\n",
    "               \n",
    "                i=0\n",
    "                for box in to_display:\n",
    "                    \n",
    "                # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "                   \n",
    "                    xmin = int(box[1])\n",
    "                    ymin = int(box[2])\n",
    "                    xmax =int(box[3])\n",
    "                    ymax =int(box[4])\n",
    "                    \n",
    "                    cv.rectangle(frame, (int(xmin), int(ymin)), (int(xmax),int(ymax)), colors[int(box[0])%len(colors)], 3)\n",
    "                    \n",
    "\n",
    "                    tracking_res.append({\"image_id\" : frameCount+1, \"category_id\" : 1, \"bbox\" : [float(xmin),float(ymin),float(xmax-xmin),float(ymax-ymin)], \"score\" : 1.0,\"id\":int(box[0])})\n",
    "                    i+=1\n",
    "                    times[dataset][detector][tracking_method].append(time.time()-start)\n",
    "                \n",
    "                out_tracking.write(frame)\n",
    "                #cv.imwrite('debug_frames/%s.jpg'%str(frameCount+1),frame)\n",
    "                frameCount+=1\n",
    "                prev_frame=frame\n",
    "                flow = None\n",
    "            # cleanup the camera and close any open windows\n",
    "\n",
    "            out_tracking.release()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            with open(json_output_path, 'w') as outfile:  \n",
    "                json.dump(tracking_res, outfile)\n",
    "                \n",
    "for k in times.keys():\n",
    "    print(k)\n",
    "    yolo = times[k]['ssd300']\n",
    "    for tr in yolo.keys():\n",
    "        print(tr,np.average(yolo[tr]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
